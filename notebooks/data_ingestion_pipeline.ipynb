{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d36b500",
   "metadata": {},
   "source": [
    "# Step-by-step Ingestion of the Adver-City Dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8db7da47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changed to root directory: /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity\n"
     ]
    }
   ],
   "source": [
    "# proper imports \n",
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "\n",
    "# define root directory\n",
    "cwd = Path.cwd()\n",
    "if cwd.name == \"notebooks\":\n",
    "    os.chdir(cwd.parent)\n",
    "    print(\"changed to root directory:\", Path.cwd())\n",
    "else:\n",
    "    print(\"already in project root:\", Path.cwd())\n",
    "\n",
    "# custom imports\n",
    "from src.ingestion import download, archive, sample, extract, label, split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30461580",
   "metadata": {},
   "source": [
    "## Configure\n",
    "\n",
    "Note: all paths will be expressed as a Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c53f7006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected prefixes:  ['rcnj', 'ri', 'unj']\n",
      "selected weather:  ['cn', 'fn', 'hrn', 'srn']\n",
      "selected density:  ['s']\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = Path.cwd()\n",
    "CONFIG_PATH = PROJECT_ROOT / \"config\" / \"config.json\"\n",
    "\n",
    "# pull configuration files\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "# data paths\n",
    "DATA_ROOT   = PROJECT_ROOT / cfg[\"data_paths\"][\"root\"]      # root directory for all data \n",
    "RAW_DIR     = PROJECT_ROOT / cfg[\"data_paths\"][\"raw\"]       # where the raw data is stored\n",
    "INDEX_DIR   = PROJECT_ROOT / cfg[\"data_paths\"][\"index\"]     # where the data index is stored\n",
    "SAMPLED_DIR = PROJECT_ROOT / cfg[\"data_paths\"][\"sampled\"]   # where the sampled data (i.e., subset) is stored\n",
    "READY_DIR   = PROJECT_ROOT / cfg[\"data_paths\"][\"ready\"]     # where the training/val/test sets are stored\n",
    "\n",
    "# make the directories \n",
    "for p in [RAW_DIR, INDEX_DIR, SAMPLED_DIR, READY_DIR]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# archive info\n",
    "BASE_URL    = cfg[\"ingestion\"][\"url\"]                       # remote location of data archive\n",
    "ARCHIVE_EXT = cfg[\"ingestion\"][\"archive_extension\"]         # archive file extension \n",
    "MANIFEST_MODE = cfg[\"ingestion\"][\"manifest_mode\"]           # mode for manifest generation (simple/verbose)\n",
    "\n",
    "# sampling \n",
    "MAX_GB      = float(cfg[\"ingestion\"][\"max_size_GB\"])        # maximum file size\n",
    "MAX_IMGS    = int(cfg[\"ingestion\"][\"images_per_archive\"])   # maximum number of images to pull\n",
    "STRIDE      = int(cfg[\"ingestion\"][\"frame_stride\"])          # gaps between frames when sampling \n",
    "SEED = int(cfg[\"reproducibility\"][\"seed\"])\n",
    "random.seed(SEED)\n",
    "CLEANUP_RAW = cfg[\"sampling\"].get(\"cleanup_raw_after_extract\", False)\n",
    "\n",
    "\n",
    "# sampling plan config\n",
    "PLAN_FILENAME = cfg[\"sampling\"][\"plan_filename\"]            # filename for sample plan\n",
    "PLAN_OVERWRITE = cfg[\"sampling\"][\"overwrite\"]               # whether to overwrite existing plan\n",
    "LABELS_FILENAME = cfg[\"sampling\"][\"labels_filename\"]        # filename for labels CSV\n",
    "\n",
    "# image info\n",
    "CAMERA     = cfg[\"ingestion\"].get(\"camera\", None)           # safer\n",
    "IMG_TYPE   = cfg[\"ingestion\"][\"image_type\"]                 # rgb\n",
    "IMG_EXT    = cfg[\"ingestion\"][\"image_extension\"]            # file extension of images \n",
    "\n",
    "# labelling info\n",
    "labels_cfg = cfg[\"labels\"]\n",
    "\n",
    "# training/splits info\n",
    "SPLITS_TRAIN = cfg[\"splits\"][\"train\"]\n",
    "SPLITS_VAL   = cfg[\"splits\"][\"val\"]\n",
    "SPLITS_TEST  = cfg[\"splits\"][\"test\"]\n",
    "\n",
    "# the valid file types\n",
    "VALID_PREFIX  = set(labels_cfg[\"valid_prefix\"])\n",
    "VALID_WEATHER = set(labels_cfg[\"valid_weather\"])\n",
    "VALID_DENSITY = set(labels_cfg[\"valid_density\"])\n",
    "\n",
    "# the files I want to download\n",
    "CHOOSE_PREFIX  = labels_cfg.get(\"choose_prefix\", labels_cfg[\"valid_prefix\"])\n",
    "CHOOSE_WEATHER = labels_cfg.get(\"choose_weather\", labels_cfg[\"valid_weather\"])\n",
    "CHOOSE_DENSITY = labels_cfg.get(\"choose_density\", labels_cfg[\"valid_density\"])\n",
    "\n",
    "# decoders (two separate label spaces)\n",
    "DECODE_TIME = labels_cfg[\"weather_decode_time\"]             # maps files to day/night\n",
    "DECODE_VIS  = labels_cfg[\"weather_decode_visibility\"]       # maps files to visibility conditions\n",
    "\n",
    "print('selected prefixes: ', CHOOSE_PREFIX)\n",
    "print('selected weather: ', CHOOSE_WEATHER)\n",
    "print('selected density: ', CHOOSE_DENSITY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6863d0e",
   "metadata": {},
   "source": [
    "## Build filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32108026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build the following filenames: \n",
      " ['rcnj_cn_s.7z', 'rcnj_fn_s.7z', 'rcnj_hrn_s.7z', 'rcnj_srn_s.7z', 'ri_cn_s.7z', 'ri_fn_s.7z', 'ri_hrn_s.7z', 'ri_srn_s.7z', 'unj_cn_s.7z', 'unj_fn_s.7z', 'unj_hrn_s.7z', 'unj_srn_s.7z']\n"
     ]
    }
   ],
   "source": [
    "# note: enforce lists for choices\n",
    "\n",
    "filenames = download.build_filenames(CHOOSE_PREFIX, CHOOSE_WEATHER, CHOOSE_DENSITY, \n",
    "                               VALID_PREFIX, VALID_WEATHER, VALID_DENSITY, \n",
    "                               ARCHIVE_EXT)\n",
    "print('build the following filenames: \\n', filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50045a3d",
   "metadata": {},
   "source": [
    "## Download from Remote Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dc3c7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] rcnj_cn_s.7z already present in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/raw.\n",
      "[SKIP] rcnj_fn_s.7z already present in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/raw.\n",
      "[SKIP] rcnj_hrn_s.7z already present in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/raw.\n",
      "[SKIP] rcnj_srn_s.7z already present in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/raw.\n",
      "[SKIP] ri_cn_s.7z already present in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/raw.\n",
      "[SKIP] ri_fn_s.7z already present in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/raw.\n",
      "[SKIP] ri_hrn_s.7z already present in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/raw.\n",
      "[SKIP] ri_srn_s.7z already present in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/raw.\n",
      "[SKIP] unj_cn_s.7z already present in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/raw.\n",
      "[SKIP] unj_fn_s.7z already present in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/raw.\n",
      "[SKIP] unj_hrn_s.7z already present in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/raw.\n",
      "[SKIP] unj_srn_s.7z already present in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/raw.\n",
      "Downloaded  12 files.\n",
      "--> rcnj_cn_s.7z\n",
      "--> rcnj_fn_s.7z\n",
      "--> rcnj_hrn_s.7z\n",
      "--> rcnj_srn_s.7z\n",
      "--> ri_cn_s.7z\n",
      "--> ri_fn_s.7z\n",
      "--> ri_hrn_s.7z\n",
      "--> ri_srn_s.7z\n",
      "--> unj_cn_s.7z\n",
      "--> unj_fn_s.7z\n",
      "--> unj_hrn_s.7z\n",
      "--> unj_srn_s.7z\n"
     ]
    }
   ],
   "source": [
    "download_raw = download.download_files(\n",
    "    base_url = BASE_URL, \n",
    "    destinations_dir = RAW_DIR, \n",
    "    filenames = filenames, \n",
    "    timeout = 60, \n",
    "    max_size_GB = MAX_GB, \n",
    "    overwrite = False\n",
    ")\n",
    "\n",
    "print('Downloaded ', len(download_raw), 'files.')\n",
    "for file in download_raw:\n",
    "    print('-->', file.name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750f55d6",
   "metadata": {},
   "source": [
    "Here is a sample of the output with some skipped and some full downloads:\n",
    "\n",
    "![sample output](img/raw_progress.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993cc260",
   "metadata": {},
   "source": [
    "## Develop Manifest\n",
    "\n",
    "Develop a manifest of the files downloaded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2d5e489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 downloaded archives\n",
      "\n",
      "[SKIP] Manifest already exists:\n",
      "  rcnj_cn_s_manifest.json\n",
      "  rcnj_cn_s.7z: 10032 lines\n",
      "[SKIP] Manifest already exists:\n",
      "  rcnj_fn_s_manifest.json\n",
      "  rcnj_fn_s.7z: 10017 lines\n",
      "[SKIP] Manifest already exists:\n",
      "  rcnj_hrn_s_manifest.json\n",
      "  rcnj_hrn_s.7z: 10025 lines\n",
      "[SKIP] Manifest already exists:\n",
      "  rcnj_srn_s_manifest.json\n",
      "  rcnj_srn_s.7z: 10032 lines\n",
      "[SKIP] Manifest already exists:\n",
      "  ri_cn_s_manifest.json\n",
      "  ri_cn_s.7z: 7781 lines\n",
      "[SKIP] Manifest already exists:\n",
      "  ri_fn_s_manifest.json\n",
      "  ri_fn_s.7z: 7755 lines\n",
      "[SKIP] Manifest already exists:\n",
      "  ri_hrn_s_manifest.json\n",
      "  ri_hrn_s.7z: 7779 lines\n",
      "[SKIP] Manifest already exists:\n",
      "  ri_srn_s_manifest.json\n",
      "  ri_srn_s.7z: 7739 lines\n",
      "[SKIP] Manifest already exists:\n",
      "  unj_cn_s_manifest.json\n",
      "  unj_cn_s.7z: 6894 lines\n",
      "[SKIP] Manifest already exists:\n",
      "  unj_fn_s_manifest.json\n",
      "  unj_fn_s.7z: 6899 lines\n",
      "[SKIP] Manifest already exists:\n",
      "  unj_hrn_s_manifest.json\n",
      "  unj_hrn_s.7z: 6899 lines\n",
      "[SKIP] Manifest already exists:\n",
      "  unj_srn_s_manifest.json\n",
      "  unj_srn_s.7z: 6894 lines\n",
      "\n",
      "Total manifests: 12\n"
     ]
    }
   ],
   "source": [
    "# index the downloaded archives (without extracting)\n",
    "archives = sorted(RAW_DIR.glob(f\"*{ARCHIVE_EXT}\"))\n",
    "print(f\"Found {len(archives)} downloaded archives\\n\")\n",
    "\n",
    "# load or create manifests\n",
    "manifests = {}\n",
    "for archive_file in archives:\n",
    "    manifest = archive.build_manifest(archive_file, INDEX_DIR, mode=MANIFEST_MODE)\n",
    "    manifests[archive_file.name] = manifest\n",
    "    print(f\"  {archive_file.name}: {len(manifest)} lines\")\n",
    "\n",
    "print(f\"\\nTotal manifests: {len(manifests)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c374132",
   "metadata": {},
   "source": [
    "Example output with some already-present files skipped: \n",
    "\n",
    "![sample output](img/manifest_out.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04da7a5e",
   "metadata": {},
   "source": [
    "## Build a Sampling Plan\n",
    "- `overwrite` an existing sampling plan if it finds one at specified location\n",
    "- the logic for `overwrite` carries forward into extract (below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3025339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rcnj_cn_s.7z:\n",
      "  Candidates: 760\n",
      "  Sampled: 760\n",
      "\n",
      "rcnj_fn_s.7z:\n",
      "  Candidates: 760\n",
      "  Sampled: 760\n",
      "\n",
      "rcnj_hrn_s.7z:\n",
      "  Candidates: 760\n",
      "  Sampled: 760\n",
      "\n",
      "rcnj_srn_s.7z:\n",
      "  Candidates: 760\n",
      "  Sampled: 760\n",
      "\n",
      "ri_cn_s.7z:\n",
      "  Candidates: 592\n",
      "  Sampled: 592\n",
      "\n",
      "ri_fn_s.7z:\n",
      "  Candidates: 592\n",
      "  Sampled: 592\n",
      "\n",
      "ri_hrn_s.7z:\n",
      "  Candidates: 592\n",
      "  Sampled: 592\n",
      "\n",
      "ri_srn_s.7z:\n",
      "  Candidates: 592\n",
      "  Sampled: 592\n",
      "\n",
      "unj_cn_s.7z:\n",
      "  Candidates: 520\n",
      "  Sampled: 520\n",
      "\n",
      "unj_fn_s.7z:\n",
      "  Candidates: 520\n",
      "  Sampled: 520\n",
      "\n",
      "unj_hrn_s.7z:\n",
      "  Candidates: 520\n",
      "  Sampled: 520\n",
      "\n",
      "unj_srn_s.7z:\n",
      "  Candidates: 520\n",
      "  Sampled: 520\n",
      "\n",
      "\n",
      "Total images to extract: 7488\n",
      "[SKIP] Sample plan already exists at /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/index/sample_plan.json. Using existing plan.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/index/sample_plan.json')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampling_plan = sample.build_sample_plan(manifests, \n",
    "                      CAMERA=CAMERA, \n",
    "                      IMG_EXT=IMG_EXT, \n",
    "                      STRIDE=STRIDE, \n",
    "                      MAX_IMGS=MAX_IMGS, \n",
    "                      SEED=SEED)\n",
    "\n",
    "print(f\"\\nTotal images to extract: {sum(len(v) for v in sampling_plan.values())}\")\n",
    "\n",
    "sample.save_sample_plan(sampling_plan, \n",
    "                        INDEX_DIR / PLAN_FILENAME,\n",
    "                        overwrite=PLAN_OVERWRITE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0aaec",
   "metadata": {},
   "source": [
    "## Extract based on Sampling Plan\n",
    "\n",
    "We have defined a few features of interest:\n",
    "- it cross-references the SAMPLED_DIR contents with the sampling plan and only accesses the archive if files are missing (saving time)\n",
    "- `overwrite`: shared from above, you may choose to overwrite existing files\n",
    "- `cleanup_raw`: we may choose to cleanup (delete) raw files after we have finished raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be37512b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rcnj_cn_s.7z:\n",
      "  Files to extract: 760\n",
      "all files in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled/rcnj_cn_s/1039/000248_camera3.png required in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled\n",
      " [SKIP] All files already extracted for rcnj_cn_s.7z\n",
      "\n",
      "rcnj_fn_s.7z:\n",
      "  Files to extract: 760\n",
      "all files in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled/rcnj_fn_s/832/000248_camera3.png required in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled\n",
      " [SKIP] All files already extracted for rcnj_fn_s.7z\n",
      "\n",
      "rcnj_hrn_s.7z:\n",
      "  Files to extract: 760\n",
      "all files in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled/rcnj_hrn_s/1700/000248_camera3.png required in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled\n",
      " [SKIP] All files already extracted for rcnj_hrn_s.7z\n",
      "\n",
      "rcnj_srn_s.7z:\n",
      "  Files to extract: 760\n",
      "all files in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled/rcnj_srn_s/165/000248_camera3.png required in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled\n",
      " [SKIP] All files already extracted for rcnj_srn_s.7z\n",
      "\n",
      "ri_cn_s.7z:\n",
      "  Files to extract: 592\n",
      "all files in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled/ri_cn_s/189/000206_camera3.png required in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled\n",
      " [SKIP] All files already extracted for ri_cn_s.7z\n",
      "\n",
      "ri_fn_s.7z:\n",
      "  Files to extract: 592\n",
      "all files in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled/ri_fn_s/1169/000206_camera3.png required in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled\n",
      " [SKIP] All files already extracted for ri_fn_s.7z\n",
      "\n",
      "ri_hrn_s.7z:\n",
      "  Files to extract: 592\n",
      "all files in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled/ri_hrn_s/189/000206_camera3.png required in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled\n",
      " [SKIP] All files already extracted for ri_hrn_s.7z\n",
      "\n",
      "ri_srn_s.7z:\n",
      "  Files to extract: 592\n",
      "all files in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled/ri_srn_s/1169/000206_camera3.png required in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled\n",
      " [SKIP] All files already extracted for ri_srn_s.7z\n",
      "\n",
      "unj_cn_s.7z:\n",
      "  Files to extract: 520\n",
      "all files in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled/unj_cn_s/257/000188_camera3.png required in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled\n",
      " [SKIP] All files already extracted for unj_cn_s.7z\n",
      "\n",
      "unj_fn_s.7z:\n",
      "  Files to extract: 520\n",
      "all files in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled/unj_fn_s/1941/000188_camera3.png required in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled\n",
      " [SKIP] All files already extracted for unj_fn_s.7z\n",
      "\n",
      "unj_hrn_s.7z:\n",
      "  Files to extract: 520\n",
      "all files in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled/unj_hrn_s/790/000188_camera3.png required in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled\n",
      " [SKIP] All files already extracted for unj_hrn_s.7z\n",
      "\n",
      "unj_srn_s.7z:\n",
      "  Files to extract: 520\n",
      "all files in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled/unj_srn_s/2474/000188_camera3.png required in /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled\n",
      " [SKIP] All files already extracted for unj_srn_s.7z\n",
      "\n",
      "==================================================\n",
      "Extraction Summary:\n",
      "  Total archives processed: 12\n",
      "  Total files extracted: 0\n",
      "  Total files skipped: 7488\n",
      "  Total errors: 0\n",
      "==================================================\n",
      "\n",
      "Extraction complete. Check SAMPLED_DIR for extracted files:\n",
      "  /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/sampled\n"
     ]
    }
   ],
   "source": [
    "# define paths\n",
    "sample_plan_file = INDEX_DIR / PLAN_FILENAME\n",
    "\n",
    "# extract files based on sampling plan\n",
    "extraction_results = extract.extract_from_sample_plan(\n",
    "    sample_plan_file=sample_plan_file,\n",
    "    raw_dir=RAW_DIR,\n",
    "    sampled_dir=SAMPLED_DIR,\n",
    "    overwrite=PLAN_OVERWRITE,\n",
    "    cleanup_raw=CLEANUP_RAW\n",
    ")\n",
    "\n",
    "print(f\"\\nExtraction complete. Check SAMPLED_DIR for extracted files:\")\n",
    "print(f\"  {SAMPLED_DIR}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e6ad24",
   "metadata": {},
   "source": [
    "Example output after extraction:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bcb4fc",
   "metadata": {},
   "source": [
    "![sample output](img/sampled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a5266",
   "metadata": {},
   "source": [
    "## Labelling \n",
    "\n",
    "Build and save a dataframe with labels and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9edfb4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] .DS_Store is not a directory\n",
      "\n",
      "Labeled 7488 images\n",
      "[SAVE] Labels saved to /Users/tjards/Library/CloudStorage/Dropbox/adjunctQueens/code/pytorch_project_advercity/data/index/labels.csv\n",
      " Total images: 7488\n",
      " Columns: ['archive_name', 'image_path', 'prefix', 'weather', 'density', 'time', 'visibility', 'agent_id', 'frame_id', 'camera_id']\n",
      " head:\n",
      "  archive_name                                         image_path prefix  \\\n",
      "0    rcnj_cn_s  /Users/tjards/Library/CloudStorage/Dropbox/adj...   rcnj   \n",
      "1    rcnj_cn_s  /Users/tjards/Library/CloudStorage/Dropbox/adj...   rcnj   \n",
      "2    rcnj_cn_s  /Users/tjards/Library/CloudStorage/Dropbox/adj...   rcnj   \n",
      "3    rcnj_cn_s  /Users/tjards/Library/CloudStorage/Dropbox/adj...   rcnj   \n",
      "4    rcnj_cn_s  /Users/tjards/Library/CloudStorage/Dropbox/adj...   rcnj   \n",
      "\n",
      "  weather density   time visibility agent_id frame_id camera_id  \n",
      "0      cn       s  night      clear       -1   000242   camera2  \n",
      "1      cn       s  night      clear       -1   000188   camera3  \n",
      "2      cn       s  night      clear       -1   000232   camera2  \n",
      "3      cn       s  night      clear       -1   000147   camera2  \n",
      "4      cn       s  night      clear       -1   000137   camera2  \n"
     ]
    }
   ],
   "source": [
    "# build labels dataframe\n",
    "labels_df = label.build_labels_df(\n",
    "    sampled_dir=SAMPLED_DIR,\n",
    "    decode_time=DECODE_TIME,\n",
    "    decode_vis=DECODE_VIS,\n",
    "    archive_ext=ARCHIVE_EXT,\n",
    "    img_ext=IMG_EXT\n",
    ")\n",
    "\n",
    "print(f\"\\nLabeled {len(labels_df)} images\")\n",
    "\n",
    "# save to CSV\n",
    "labels_csv = label.save_labels(\n",
    "    df = labels_df, \n",
    "    output_path = INDEX_DIR / LABELS_FILENAME,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d560a2aa",
   "metadata": {},
   "source": [
    "Example output:\n",
    "\n",
    "![sample output](img/labeled.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7f2ece",
   "metadata": {},
   "source": [
    "## Create Train/Val/Test sets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cf11f5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822e66dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "split_labels() got an unexpected keyword argument 'labels_csv_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m splits = \u001b[43msplit\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit_labels\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels_csv_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mINDEX_DIR\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mLABELS_FILENAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSPLITS_TRAIN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSPLITS_VAL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSPLITS_TEST\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Check results\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrain: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(splits[\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m images\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: split_labels() got an unexpected keyword argument 'labels_csv_path'"
     ]
    }
   ],
   "source": [
    "splits = split.split_labels(\n",
    "    labels_path=INDEX_DIR / LABELS_FILENAME,\n",
    "    train_ratio=SPLITS_TRAIN,\n",
    "    val_ratio=SPLITS_VAL,\n",
    "    test_ratio=SPLITS_TEST\n",
    ")\n",
    "\n",
    "# Check results\n",
    "print(f\"Train: {len(splits['train'])} images\")\n",
    "print(f\"Val: {len(splits['val'])} images\")\n",
    "print(f\"Test: {len(splits['test'])} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83131f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
